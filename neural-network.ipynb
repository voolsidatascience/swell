{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/data/final/train.csv').drop(columns=\"datasetId\")\n",
    "test = pd.read_csv('dataset/data/final/test.csv').drop(columns=\"datasetId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_train = train.drop(columns='condition').to_numpy()\n",
    "y_train = train['condition'].to_numpy()\n",
    "\n",
    "# test\n",
    "X_test = test.drop(columns='condition').to_numpy()\n",
    "y_test = test['condition'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# encode labels\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "y_train = one_hot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = one_hot_encoder.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Function to create model\n",
    "def create_model():\n",
    "    # create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(16, input_dim=34, activation='relu'))\n",
    "\tmodel.add(Dense(8, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 369289 samples, validate on 41033 samples\n",
      "Epoch 1/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.7620 - accuracy: 0.6609 - val_loss: 0.6326 - val_accuracy: 0.7273\n",
      "Epoch 2/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.5638 - accuracy: 0.7650 - val_loss: 0.5264 - val_accuracy: 0.7822\n",
      "Epoch 3/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.4852 - accuracy: 0.8092 - val_loss: 0.4704 - val_accuracy: 0.8139\n",
      "Epoch 4/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.4482 - accuracy: 0.8236 - val_loss: 0.4395 - val_accuracy: 0.8232\n",
      "Epoch 5/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.4219 - accuracy: 0.8367 - val_loss: 0.4025 - val_accuracy: 0.8492\n",
      "Epoch 6/150\n",
      "369289/369289 [==============================] - 16s 42us/step - loss: 0.4000 - accuracy: 0.8478 - val_loss: 0.3946 - val_accuracy: 0.8535\n",
      "Epoch 7/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.3816 - accuracy: 0.8569 - val_loss: 0.3655 - val_accuracy: 0.8670\n",
      "Epoch 8/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.3665 - accuracy: 0.8635 - val_loss: 0.3743 - val_accuracy: 0.8610\n",
      "Epoch 9/150\n",
      "369289/369289 [==============================] - 16s 42us/step - loss: 0.3542 - accuracy: 0.8687 - val_loss: 0.3551 - val_accuracy: 0.8708\n",
      "Epoch 10/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.3436 - accuracy: 0.8728 - val_loss: 0.3380 - val_accuracy: 0.8766\n",
      "Epoch 11/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.3351 - accuracy: 0.8766 - val_loss: 0.3319 - val_accuracy: 0.8807\n",
      "Epoch 12/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.3279 - accuracy: 0.8799 - val_loss: 0.3400 - val_accuracy: 0.8690\n",
      "Epoch 13/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.3208 - accuracy: 0.8827 - val_loss: 0.3162 - val_accuracy: 0.8839\n",
      "Epoch 14/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.3144 - accuracy: 0.8858 - val_loss: 0.3242 - val_accuracy: 0.8770\n",
      "Epoch 15/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.3084 - accuracy: 0.8877 - val_loss: 0.2970 - val_accuracy: 0.8947\n",
      "Epoch 16/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.3038 - accuracy: 0.8886 - val_loss: 0.2938 - val_accuracy: 0.8938\n",
      "Epoch 17/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2996 - accuracy: 0.8904 - val_loss: 0.2912 - val_accuracy: 0.8930\n",
      "Epoch 18/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2945 - accuracy: 0.8914 - val_loss: 0.3208 - val_accuracy: 0.8764\n",
      "Epoch 19/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2897 - accuracy: 0.8932 - val_loss: 0.3138 - val_accuracy: 0.8816\n",
      "Epoch 20/150\n",
      "369289/369289 [==============================] - 17s 45us/step - loss: 0.2863 - accuracy: 0.8936 - val_loss: 0.3142 - val_accuracy: 0.8826\n",
      "Epoch 21/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2830 - accuracy: 0.8947 - val_loss: 0.3061 - val_accuracy: 0.8817\n",
      "Epoch 22/150\n",
      "369289/369289 [==============================] - 17s 45us/step - loss: 0.2792 - accuracy: 0.8957 - val_loss: 0.3184 - val_accuracy: 0.8761\n",
      "Epoch 23/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2763 - accuracy: 0.8961 - val_loss: 0.3233 - val_accuracy: 0.8744\n",
      "Epoch 24/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2735 - accuracy: 0.8965 - val_loss: 0.2941 - val_accuracy: 0.8837\n",
      "Epoch 25/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2695 - accuracy: 0.8969 - val_loss: 0.2959 - val_accuracy: 0.8863\n",
      "Epoch 26/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2663 - accuracy: 0.8975 - val_loss: 0.2882 - val_accuracy: 0.8912\n",
      "Epoch 27/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2630 - accuracy: 0.8992 - val_loss: 0.2996 - val_accuracy: 0.8846\n",
      "Epoch 28/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2599 - accuracy: 0.9005 - val_loss: 0.2512 - val_accuracy: 0.9055\n",
      "Epoch 29/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2578 - accuracy: 0.9010 - val_loss: 0.2575 - val_accuracy: 0.9012\n",
      "Epoch 30/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2553 - accuracy: 0.9019 - val_loss: 0.2543 - val_accuracy: 0.9027\n",
      "Epoch 31/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2522 - accuracy: 0.9031 - val_loss: 0.2725 - val_accuracy: 0.8977\n",
      "Epoch 32/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2500 - accuracy: 0.9041 - val_loss: 0.2652 - val_accuracy: 0.8983\n",
      "Epoch 33/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2473 - accuracy: 0.9055 - val_loss: 0.2587 - val_accuracy: 0.9010\n",
      "Epoch 34/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2437 - accuracy: 0.9076 - val_loss: 0.2430 - val_accuracy: 0.9052\n",
      "Epoch 35/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2416 - accuracy: 0.9080 - val_loss: 0.2408 - val_accuracy: 0.9111\n",
      "Epoch 36/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2383 - accuracy: 0.9095 - val_loss: 0.2595 - val_accuracy: 0.9033\n",
      "Epoch 37/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2365 - accuracy: 0.9099 - val_loss: 0.2440 - val_accuracy: 0.9078\n",
      "Epoch 38/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2338 - accuracy: 0.9114 - val_loss: 0.2274 - val_accuracy: 0.9160\n",
      "Epoch 39/150\n",
      "369289/369289 [==============================] - 17s 46us/step - loss: 0.2316 - accuracy: 0.9124 - val_loss: 0.2446 - val_accuracy: 0.9063\n",
      "Epoch 40/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2301 - accuracy: 0.9128 - val_loss: 0.2711 - val_accuracy: 0.8990\n",
      "Epoch 41/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2283 - accuracy: 0.9138 - val_loss: 0.2316 - val_accuracy: 0.9131\n",
      "Epoch 42/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.2268 - accuracy: 0.9145 - val_loss: 0.2611 - val_accuracy: 0.8972\n",
      "Epoch 43/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2252 - accuracy: 0.9151 - val_loss: 0.2464 - val_accuracy: 0.9086\n",
      "Epoch 44/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2227 - accuracy: 0.9160 - val_loss: 0.2694 - val_accuracy: 0.8968\n",
      "Epoch 45/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2214 - accuracy: 0.9171 - val_loss: 0.2453 - val_accuracy: 0.9096\n",
      "Epoch 46/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2188 - accuracy: 0.9174 - val_loss: 0.2580 - val_accuracy: 0.9014\n",
      "Epoch 47/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2159 - accuracy: 0.9192 - val_loss: 0.2771 - val_accuracy: 0.8902\n",
      "Epoch 48/150\n",
      "369289/369289 [==============================] - 16s 45us/step - loss: 0.2137 - accuracy: 0.9203 - val_loss: 0.2153 - val_accuracy: 0.9220\n",
      "Epoch 49/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2129 - accuracy: 0.9205 - val_loss: 0.2328 - val_accuracy: 0.9145\n",
      "Epoch 50/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2109 - accuracy: 0.9214 - val_loss: 0.2206 - val_accuracy: 0.9186\n",
      "Epoch 51/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2107 - accuracy: 0.9215 - val_loss: 0.2329 - val_accuracy: 0.9155\n",
      "Epoch 52/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.2082 - accuracy: 0.9228 - val_loss: 0.2456 - val_accuracy: 0.9044\n",
      "Epoch 53/150\n",
      "369289/369289 [==============================] - 17s 45us/step - loss: 0.2076 - accuracy: 0.9228 - val_loss: 0.2374 - val_accuracy: 0.9128\n",
      "Epoch 54/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.2064 - accuracy: 0.9235 - val_loss: 0.2859 - val_accuracy: 0.8984\n",
      "Epoch 55/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.2048 - accuracy: 0.9247 - val_loss: 0.2417 - val_accuracy: 0.9106\n",
      "Epoch 56/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.2036 - accuracy: 0.9248 - val_loss: 0.2151 - val_accuracy: 0.9195\n",
      "Epoch 57/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.2025 - accuracy: 0.9255 - val_loss: 0.2305 - val_accuracy: 0.9150\n",
      "Epoch 58/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.2020 - accuracy: 0.9258 - val_loss: 0.2349 - val_accuracy: 0.9071\n",
      "Epoch 59/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.2002 - accuracy: 0.9262 - val_loss: 0.2222 - val_accuracy: 0.9182\n",
      "Epoch 60/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1995 - accuracy: 0.9269 - val_loss: 0.2158 - val_accuracy: 0.9217\n",
      "Epoch 61/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1992 - accuracy: 0.9270 - val_loss: 0.2018 - val_accuracy: 0.9253\n",
      "Epoch 62/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1977 - accuracy: 0.9276 - val_loss: 0.2017 - val_accuracy: 0.9253\n",
      "Epoch 63/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1967 - accuracy: 0.9277 - val_loss: 0.2148 - val_accuracy: 0.9210\n",
      "Epoch 64/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1963 - accuracy: 0.9281 - val_loss: 0.2101 - val_accuracy: 0.9236\n",
      "Epoch 65/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1952 - accuracy: 0.9284 - val_loss: 0.2004 - val_accuracy: 0.9264\n",
      "Epoch 66/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1947 - accuracy: 0.9284 - val_loss: 0.2076 - val_accuracy: 0.9241\n",
      "Epoch 67/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1932 - accuracy: 0.9294 - val_loss: 0.2143 - val_accuracy: 0.9218\n",
      "Epoch 68/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1925 - accuracy: 0.9293 - val_loss: 0.2335 - val_accuracy: 0.9135\n",
      "Epoch 69/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1922 - accuracy: 0.9299 - val_loss: 0.2110 - val_accuracy: 0.9229\n",
      "Epoch 70/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1922 - accuracy: 0.9296 - val_loss: 0.1931 - val_accuracy: 0.9303\n",
      "Epoch 71/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.1906 - accuracy: 0.9303 - val_loss: 0.2253 - val_accuracy: 0.9160\n",
      "Epoch 72/150\n",
      "369289/369289 [==============================] - 16s 42us/step - loss: 0.1902 - accuracy: 0.9307 - val_loss: 0.2158 - val_accuracy: 0.9184\n",
      "Epoch 73/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1900 - accuracy: 0.9306 - val_loss: 0.2136 - val_accuracy: 0.9216\n",
      "Epoch 74/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1893 - accuracy: 0.9310 - val_loss: 0.1924 - val_accuracy: 0.9291\n",
      "Epoch 75/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1888 - accuracy: 0.9310 - val_loss: 0.1969 - val_accuracy: 0.9284\n",
      "Epoch 76/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1872 - accuracy: 0.9317 - val_loss: 0.2121 - val_accuracy: 0.9226\n",
      "Epoch 77/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1865 - accuracy: 0.9321 - val_loss: 0.2002 - val_accuracy: 0.9280\n",
      "Epoch 78/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1859 - accuracy: 0.9325 - val_loss: 0.2397 - val_accuracy: 0.9099\n",
      "Epoch 79/150\n",
      "369289/369289 [==============================] - 16s 42us/step - loss: 0.1862 - accuracy: 0.9318 - val_loss: 0.1894 - val_accuracy: 0.9299\n",
      "Epoch 80/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1842 - accuracy: 0.9328 - val_loss: 0.1918 - val_accuracy: 0.9294\n",
      "Epoch 81/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1836 - accuracy: 0.9329 - val_loss: 0.1878 - val_accuracy: 0.9336\n",
      "Epoch 82/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1829 - accuracy: 0.9334 - val_loss: 0.2023 - val_accuracy: 0.9268\n",
      "Epoch 83/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.2007 - val_accuracy: 0.9255\n",
      "Epoch 84/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1821 - accuracy: 0.9335 - val_loss: 0.1813 - val_accuracy: 0.9351\n",
      "Epoch 85/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1807 - accuracy: 0.9343 - val_loss: 0.2403 - val_accuracy: 0.9069\n",
      "Epoch 86/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1791 - accuracy: 0.9349 - val_loss: 0.1938 - val_accuracy: 0.9279\n",
      "Epoch 87/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1796 - accuracy: 0.9347 - val_loss: 0.1815 - val_accuracy: 0.9326\n",
      "Epoch 88/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1785 - accuracy: 0.9353 - val_loss: 0.1875 - val_accuracy: 0.9319\n",
      "Epoch 89/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1784 - accuracy: 0.9349 - val_loss: 0.2036 - val_accuracy: 0.9237\n",
      "Epoch 90/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1773 - accuracy: 0.9359 - val_loss: 0.1978 - val_accuracy: 0.9281\n",
      "Epoch 91/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1768 - accuracy: 0.9359 - val_loss: 0.1978 - val_accuracy: 0.9272\n",
      "Epoch 92/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1760 - accuracy: 0.9359 - val_loss: 0.2169 - val_accuracy: 0.9201\n",
      "Epoch 93/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1750 - accuracy: 0.9365 - val_loss: 0.2326 - val_accuracy: 0.9146\n",
      "Epoch 94/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1745 - accuracy: 0.9368 - val_loss: 0.1892 - val_accuracy: 0.9295\n",
      "Epoch 95/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1740 - accuracy: 0.9368 - val_loss: 0.1806 - val_accuracy: 0.9355\n",
      "Epoch 96/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1738 - accuracy: 0.9369 - val_loss: 0.1878 - val_accuracy: 0.9298\n",
      "Epoch 97/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1734 - accuracy: 0.9371 - val_loss: 0.1954 - val_accuracy: 0.9286\n",
      "Epoch 98/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1724 - accuracy: 0.9374 - val_loss: 0.1922 - val_accuracy: 0.9301\n",
      "Epoch 99/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1722 - accuracy: 0.9374 - val_loss: 0.2273 - val_accuracy: 0.9180\n",
      "Epoch 100/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1715 - accuracy: 0.9380 - val_loss: 0.1713 - val_accuracy: 0.9376\n",
      "Epoch 101/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1714 - accuracy: 0.9378 - val_loss: 0.1827 - val_accuracy: 0.9347\n",
      "Epoch 102/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1701 - accuracy: 0.9381 - val_loss: 0.1816 - val_accuracy: 0.9347\n",
      "Epoch 103/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1698 - accuracy: 0.9387 - val_loss: 0.2123 - val_accuracy: 0.9221\n",
      "Epoch 104/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1689 - accuracy: 0.9390 - val_loss: 0.2447 - val_accuracy: 0.9119\n",
      "Epoch 105/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1690 - accuracy: 0.9388 - val_loss: 0.2131 - val_accuracy: 0.9206\n",
      "Epoch 106/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1688 - accuracy: 0.9388 - val_loss: 0.2381 - val_accuracy: 0.9056\n",
      "Epoch 107/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1677 - accuracy: 0.9389 - val_loss: 0.2027 - val_accuracy: 0.9240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1668 - accuracy: 0.9394 - val_loss: 0.1805 - val_accuracy: 0.9336\n",
      "Epoch 109/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1659 - accuracy: 0.9396 - val_loss: 0.1677 - val_accuracy: 0.9386\n",
      "Epoch 110/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1651 - accuracy: 0.9402 - val_loss: 0.1897 - val_accuracy: 0.9289\n",
      "Epoch 111/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1640 - accuracy: 0.9405 - val_loss: 0.1858 - val_accuracy: 0.9298\n",
      "Epoch 112/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1641 - accuracy: 0.9403 - val_loss: 0.1854 - val_accuracy: 0.9313\n",
      "Epoch 113/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1637 - accuracy: 0.9408 - val_loss: 0.1822 - val_accuracy: 0.9329\n",
      "Epoch 114/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1634 - accuracy: 0.9404 - val_loss: 0.1772 - val_accuracy: 0.9344\n",
      "Epoch 115/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1630 - accuracy: 0.9407 - val_loss: 0.1802 - val_accuracy: 0.9336\n",
      "Epoch 116/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1624 - accuracy: 0.9412 - val_loss: 0.2027 - val_accuracy: 0.9236\n",
      "Epoch 117/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1624 - accuracy: 0.9410 - val_loss: 0.1927 - val_accuracy: 0.9271\n",
      "Epoch 118/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1612 - accuracy: 0.9418 - val_loss: 0.1867 - val_accuracy: 0.9304\n",
      "Epoch 119/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1609 - accuracy: 0.9414 - val_loss: 0.1927 - val_accuracy: 0.9271\n",
      "Epoch 120/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1603 - accuracy: 0.9414 - val_loss: 0.1991 - val_accuracy: 0.9252\n",
      "Epoch 121/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1594 - accuracy: 0.9422 - val_loss: 0.2029 - val_accuracy: 0.9221\n",
      "Epoch 122/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1607 - accuracy: 0.9418 - val_loss: 0.2022 - val_accuracy: 0.9221\n",
      "Epoch 123/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1608 - accuracy: 0.9413 - val_loss: 0.1951 - val_accuracy: 0.9283\n",
      "Epoch 124/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1599 - accuracy: 0.9418 - val_loss: 0.1926 - val_accuracy: 0.9274\n",
      "Epoch 125/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1585 - accuracy: 0.9423 - val_loss: 0.2000 - val_accuracy: 0.9257\n",
      "Epoch 126/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1584 - accuracy: 0.9423 - val_loss: 0.2358 - val_accuracy: 0.9123\n",
      "Epoch 127/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1581 - accuracy: 0.9424 - val_loss: 0.1877 - val_accuracy: 0.9304\n",
      "Epoch 128/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1582 - accuracy: 0.9427 - val_loss: 0.1840 - val_accuracy: 0.9320\n",
      "Epoch 129/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1580 - accuracy: 0.9428 - val_loss: 0.1993 - val_accuracy: 0.9236\n",
      "Epoch 130/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1572 - accuracy: 0.9431 - val_loss: 0.1840 - val_accuracy: 0.9343\n",
      "Epoch 131/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1576 - accuracy: 0.9428 - val_loss: 0.1911 - val_accuracy: 0.9283\n",
      "Epoch 132/150\n",
      "369289/369289 [==============================] - 15s 40us/step - loss: 0.1568 - accuracy: 0.9430 - val_loss: 0.1861 - val_accuracy: 0.9324\n",
      "Epoch 133/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1570 - accuracy: 0.9430 - val_loss: 0.1859 - val_accuracy: 0.9305\n",
      "Epoch 134/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1565 - accuracy: 0.9429 - val_loss: 0.2141 - val_accuracy: 0.9232\n",
      "Epoch 135/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1565 - accuracy: 0.9432 - val_loss: 0.1760 - val_accuracy: 0.9337\n",
      "Epoch 136/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1568 - accuracy: 0.9431 - val_loss: 0.1729 - val_accuracy: 0.9381\n",
      "Epoch 137/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1564 - accuracy: 0.9428 - val_loss: 0.1976 - val_accuracy: 0.9269\n",
      "Epoch 138/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1558 - accuracy: 0.9435 - val_loss: 0.1621 - val_accuracy: 0.9419\n",
      "Epoch 139/150\n",
      "369289/369289 [==============================] - 16s 43us/step - loss: 0.1549 - accuracy: 0.9439 - val_loss: 0.2166 - val_accuracy: 0.9155\n",
      "Epoch 140/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1551 - accuracy: 0.9436 - val_loss: 0.1808 - val_accuracy: 0.9330\n",
      "Epoch 141/150\n",
      "369289/369289 [==============================] - 16s 44us/step - loss: 0.1548 - accuracy: 0.9440 - val_loss: 0.1748 - val_accuracy: 0.9354\n",
      "Epoch 142/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1544 - accuracy: 0.9440 - val_loss: 0.1840 - val_accuracy: 0.9320\n",
      "Epoch 143/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1540 - accuracy: 0.9440 - val_loss: 0.2112 - val_accuracy: 0.9214\n",
      "Epoch 144/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1541 - accuracy: 0.9442 - val_loss: 0.1701 - val_accuracy: 0.9382\n",
      "Epoch 145/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1543 - accuracy: 0.9440 - val_loss: 0.1860 - val_accuracy: 0.9282\n",
      "Epoch 146/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1535 - accuracy: 0.9440 - val_loss: 0.1761 - val_accuracy: 0.9332\n",
      "Epoch 147/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1530 - accuracy: 0.9442 - val_loss: 0.2033 - val_accuracy: 0.9238\n",
      "Epoch 148/150\n",
      "369289/369289 [==============================] - 15s 42us/step - loss: 0.1525 - accuracy: 0.9446 - val_loss: 0.1915 - val_accuracy: 0.9296\n",
      "Epoch 149/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1525 - accuracy: 0.9445 - val_loss: 0.1935 - val_accuracy: 0.9268\n",
      "Epoch 150/150\n",
      "369289/369289 [==============================] - 15s 41us/step - loss: 0.1531 - accuracy: 0.9442 - val_loss: 0.2622 - val_accuracy: 0.9097\n",
      "41033/41033 [==============================] - 0s 11us/step\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "print('Training model...')\n",
    "\n",
    "batch_size = 64 # \n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=150,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to a single file\n",
    "model.save(\"best_model.h5\")\n",
    "print(\"Model saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "converter = lite.TFLiteConverter.from_keras_model_file(\"best_model.h5\")\n",
    "model = converter.convert()\n",
    "\n",
    "with open(\"best_model.tflite\", \"wb\") as file:\n",
    "    file.write(model)\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
